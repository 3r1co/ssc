{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction This training material is part of the Secure Supply Chain Course of ISEN Toulon. The course takes place over four days and intends to give students an overview of all technologies that are revolving around Continuous Integration and Delivery with a special focus on \"cloud\" technologies. Day 1 Prerequisites Docker Lab Kubernetes Lab Getting Started on Github Github Actions CI with Github Actions and Docker Day 2 Getting Started with AWS Cloudformation Deployment Deploy Containers with ECS Cloudformation Linting EKS deployment Day 3 Juice Shop Static Code Analysis 3rd Party Dependency Check Container Vulnerability Scanning Dynamic Application Security Scanning Day 4 Jenkins CI Server Build Docker with Jenkins and Kaniko Kubernetes Pod Security Policies Kubernetes Network Security Policies Write your own Gitub Action DefectDojo","title":"Home"},{"location":"#introduction","text":"This training material is part of the Secure Supply Chain Course of ISEN Toulon. The course takes place over four days and intends to give students an overview of all technologies that are revolving around Continuous Integration and Delivery with a special focus on \"cloud\" technologies.","title":"Introduction"},{"location":"#day-1","text":"Prerequisites Docker Lab Kubernetes Lab Getting Started on Github Github Actions CI with Github Actions and Docker","title":"Day 1"},{"location":"#day-2","text":"Getting Started with AWS Cloudformation Deployment Deploy Containers with ECS Cloudformation Linting EKS deployment","title":"Day 2"},{"location":"#day-3","text":"Juice Shop Static Code Analysis 3rd Party Dependency Check Container Vulnerability Scanning Dynamic Application Security Scanning","title":"Day 3"},{"location":"#day-4","text":"Jenkins CI Server Build Docker with Jenkins and Kaniko Kubernetes Pod Security Policies Kubernetes Network Security Policies Write your own Gitub Action DefectDojo","title":"Day 4"},{"location":"actions/","text":"Github Actions (1 hour) The goal of this exercise is to show you how to create a CI/CD Pipeline for containerized applications. For this Lab, we will use the automation platform of Github, called Github Actions. At the end of the exercise, should have added a Github Actions YAML file to your repository and on each commit and push to the master branch, a new Docker image should be built automatically.","title":"Github Actions"},{"location":"actions/#github-actions-1-hour","text":"The goal of this exercise is to show you how to create a CI/CD Pipeline for containerized applications. For this Lab, we will use the automation platform of Github, called Github Actions. At the end of the exercise, should have added a Github Actions YAML file to your repository and on each commit and push to the master branch, a new Docker image should be built automatically.","title":"Github Actions (1 hour)"},{"location":"arachni/","text":"Dynamic Application Security Scanning (1 hour) Similar to ZAP Proxy, Arachni is a DAST tool that is intended to run on the command line. Unfortunately, there is no Github Action available for this tool, so your task today is to write your own Github Action, including Arachni and performing a scan on your application. A good starting point is here . To succeed, you will have to build a Docker image containing arachni with an entrypoint as described in the documentation.","title":"Write your own Github Action"},{"location":"arachni/#dynamic-application-security-scanning-1-hour","text":"Similar to ZAP Proxy, Arachni is a DAST tool that is intended to run on the command line. Unfortunately, there is no Github Action available for this tool, so your task today is to write your own Github Action, including Arachni and performing a scan on your application. A good starting point is here . To succeed, you will have to build a Docker image containing arachni with an entrypoint as described in the documentation.","title":"Dynamic Application Security Scanning (1 hour)"},{"location":"aws/","text":"AWS Labs (1 hour) In this lab, you'll learn How to connect to AWS from your workstation How to design an Infrastructure as Code (IaC) file with the help of Troposphere How to deploy this file in your Development environment How to deliver this file through the Infrastructure Automation Pipeline to Production Connect to AWS Educate Go to www.awseducate.com and log in with your ISEN E-Mail address. You should have already received an invitation. AWS Connection setup In this chapter, we'll explain you how to connect with the AWS CLI to your AWS Account. In the AWS Edcuate console, click on \"My Classrooms\". In the line of \"Supply Chain Security\", click on \"Go to classroom\". Confirm with \"Continue\". In the new window, click on \"Account details\". In the pop-up window, click on the \"Show\" button next to \"AWS CLI:\". Copy and paste the content in the shown box to %HOME%/.aws/credentials . In a terminal, type the following: aws configure Enter us-east-1 as default region and leave the default output empty. This information will be stored in %HOME%/.aws/config . Verify that you have access to the training account: aws ec2 describe-instances CloudFormation Let's now deploy your first resource in the development account. Download the following file to your \"CloudAwarenessLab\" folder: cloudformation.yaml This file deploys a single EC2 instance. Deploy the EC2 instance with the help of CloudFormation: aws cloudformation deploy --template-file cloudformation.yaml --stack-name <your-login>-stack Wait until the stack is deployed and check if your instance is visible: aws ec2 describe-instances Follow up exercise Modify the CloudFormation template in order to add a Security Group which allows access on Port 443 to your EC2 instance. Troposphere Another way to generate CloudFormation templates is to use a framework for a programming language. One famous example is Troposphere, a Python Framework. The advantage of using a framework over bare CloudFormation is that you can use logic, conditions and loops when defining your infrastructure, so in short, it gives more flexibility when building it. In this example, we'll generate another EC2 instance. Download the following file to your \"CloudAwarenessLab\" folder: ec2_instance.py After you understood the logic of the file, let's deploy it now. Generate CloudFormation from the Python script: python ec2_instance.py > ec2_instance.yml Deploy the CloudFormation stack: aws cloudformation deploy --template-file ec2_instance.yml --stack-name <your-ldap-login>-ts-stack Follow up exercise Package the EC2 Instance in a Launch Configuration that is referenced by an Auto Scaling Group. You can find an example here . Deploy this template and verify that that your EC2 instance is backed by an Autoscaling group (have a look at the instance tags).","title":"Getting Started with AWS"},{"location":"aws/#aws-labs-1-hour","text":"In this lab, you'll learn How to connect to AWS from your workstation How to design an Infrastructure as Code (IaC) file with the help of Troposphere How to deploy this file in your Development environment How to deliver this file through the Infrastructure Automation Pipeline to Production","title":"AWS Labs (1 hour)"},{"location":"aws/#connect-to-aws-educate","text":"Go to www.awseducate.com and log in with your ISEN E-Mail address. You should have already received an invitation.","title":"Connect to AWS Educate"},{"location":"aws/#aws-connection-setup","text":"In this chapter, we'll explain you how to connect with the AWS CLI to your AWS Account. In the AWS Edcuate console, click on \"My Classrooms\". In the line of \"Supply Chain Security\", click on \"Go to classroom\". Confirm with \"Continue\". In the new window, click on \"Account details\". In the pop-up window, click on the \"Show\" button next to \"AWS CLI:\". Copy and paste the content in the shown box to %HOME%/.aws/credentials . In a terminal, type the following: aws configure Enter us-east-1 as default region and leave the default output empty. This information will be stored in %HOME%/.aws/config . Verify that you have access to the training account: aws ec2 describe-instances","title":"AWS Connection setup"},{"location":"aws/#cloudformation","text":"Let's now deploy your first resource in the development account. Download the following file to your \"CloudAwarenessLab\" folder: cloudformation.yaml This file deploys a single EC2 instance. Deploy the EC2 instance with the help of CloudFormation: aws cloudformation deploy --template-file cloudformation.yaml --stack-name <your-login>-stack Wait until the stack is deployed and check if your instance is visible: aws ec2 describe-instances","title":"CloudFormation"},{"location":"aws/#follow-up-exercise","text":"Modify the CloudFormation template in order to add a Security Group which allows access on Port 443 to your EC2 instance.","title":"Follow up exercise"},{"location":"aws/#troposphere","text":"Another way to generate CloudFormation templates is to use a framework for a programming language. One famous example is Troposphere, a Python Framework. The advantage of using a framework over bare CloudFormation is that you can use logic, conditions and loops when defining your infrastructure, so in short, it gives more flexibility when building it. In this example, we'll generate another EC2 instance. Download the following file to your \"CloudAwarenessLab\" folder: ec2_instance.py After you understood the logic of the file, let's deploy it now. Generate CloudFormation from the Python script: python ec2_instance.py > ec2_instance.yml Deploy the CloudFormation stack: aws cloudformation deploy --template-file ec2_instance.yml --stack-name <your-ldap-login>-ts-stack","title":"Troposphere"},{"location":"aws/#follow-up-exercise_1","text":"Package the EC2 Instance in a Launch Configuration that is referenced by an Auto Scaling Group. You can find an example here . Deploy this template and verify that that your EC2 instance is backed by an Autoscaling group (have a look at the instance tags).","title":"Follow up exercise"},{"location":"cfn-nag/","text":"Cloudformation Linting (1 hour) As you saw in the presentation, all layers of your application must be properly secured. This what we call Defense in Depth . The lowest layer in a public cloud deployment is the infrastructure and in the case of AWS, we are deploying it through CloudFormation. There can be very common pitfalls when it comes to Infrastructure as Code, so it can be very advantageous to automate the scan for these. One very known tools is cfn-nag . There is already a Github Action available for this tool here . Please scan the following file: cf-all.yaml In this exercise, integrate this lint program into your Github workflow and do the validation before you actually deploy resources in AWS. Also, fix all issues that are reported through the scanner.","title":"Cloudformation Linting"},{"location":"cfn-nag/#cloudformation-linting-1-hour","text":"As you saw in the presentation, all layers of your application must be properly secured. This what we call Defense in Depth . The lowest layer in a public cloud deployment is the infrastructure and in the case of AWS, we are deploying it through CloudFormation. There can be very common pitfalls when it comes to Infrastructure as Code, so it can be very advantageous to automate the scan for these. One very known tools is cfn-nag . There is already a Github Action available for this tool here . Please scan the following file: cf-all.yaml In this exercise, integrate this lint program into your Github workflow and do the validation before you actually deploy resources in AWS. Also, fix all issues that are reported through the scanner.","title":"Cloudformation Linting (1 hour)"},{"location":"clair/","text":"Docker Vulnerability Scanning with Clair (1 hour) So far, we uncovered vulnerabilities in your application source third party libraries in your application your infrastructure as code Another vulnerability factor can be the libraries that are integrated in your operating system, or in the case of Docker, your Docker image. A famous open source vulnerability scanner for Docker images CoreOS Clair . For the purpose of this course, there is centralized Clair instance running at clair.3r1.co . Your task is now to perform a vulnerability scan of your Docker image with klar . Here a way to run the clair scan: - name: use klar run: | wget https://github.com/optiopay/klar/releases/download/v2.4.0/klar-2.4.0-linux-amd64 -O klar chmod +x klar CLAIR_ADDR=http://clair.3r1.co:6060 ./klar docker.io/<your-username>/<your-image>:<sha-tag>","title":"Container Vulnerability Scanning with Clair"},{"location":"clair/#docker-vulnerability-scanning-with-clair-1-hour","text":"So far, we uncovered vulnerabilities in your application source third party libraries in your application your infrastructure as code Another vulnerability factor can be the libraries that are integrated in your operating system, or in the case of Docker, your Docker image. A famous open source vulnerability scanner for Docker images CoreOS Clair . For the purpose of this course, there is centralized Clair instance running at clair.3r1.co . Your task is now to perform a vulnerability scan of your Docker image with klar . Here a way to run the clair scan: - name: use klar run: | wget https://github.com/optiopay/klar/releases/download/v2.4.0/klar-2.4.0-linux-amd64 -O klar chmod +x klar CLAIR_ADDR=http://clair.3r1.co:6060 ./klar docker.io/<your-username>/<your-image>:<sha-tag>","title":"Docker Vulnerability Scanning with Clair (1 hour)"},{"location":"cloudformation/","text":"Cloudformation Deployment through Github Actions (1 hour) This exercise is building up on exercise 2.1 (Getting started with AWS). The goal of this exercise is to automate the deployment of AWS resources once a change to the master branch of a repository occured. To perform this exercise: Add the cloudformation.yaml file from exercise 2.1 in your repository Extend your Github Workflow to perform the aws cloudformation deploy --template-file cloudformation.yaml --stack-name <your-login>-stack command","title":"Cloudformation Deployment"},{"location":"cloudformation/#cloudformation-deployment-through-github-actions-1-hour","text":"This exercise is building up on exercise 2.1 (Getting started with AWS). The goal of this exercise is to automate the deployment of AWS resources once a change to the master branch of a repository occured. To perform this exercise: Add the cloudformation.yaml file from exercise 2.1 in your repository Extend your Github Workflow to perform the aws cloudformation deploy --template-file cloudformation.yaml --stack-name <your-login>-stack command","title":"Cloudformation Deployment through Github Actions (1 hour)"},{"location":"defectdojo/","text":"Set up the Defect Dojo The DefectDojo is a central place to store all findings of vulnerabilities and flaws that were found by various scanners. The Documentation can be found here . You can install the DefectDojo in Kubernetes using these instructions. Your goal is to upload the findings that discovered when you scanned the Juice Shop. Please follow the according instructions here .","title":"DefectDojo"},{"location":"defectdojo/#set-up-the-defect-dojo","text":"The DefectDojo is a central place to store all findings of vulnerabilities and flaws that were found by various scanners. The Documentation can be found here . You can install the DefectDojo in Kubernetes using these instructions. Your goal is to upload the findings that discovered when you scanned the Juice Shop. Please follow the according instructions here .","title":"Set up the Defect Dojo"},{"location":"dependency-check/","text":"Static Code Analysis with OWASP Dependency Check (1 hour) After scanning your source code with Sonar, we now need to analyze the dependencies of your application, as they can also introduce vulnerabilities to your application. One very famous tool to do so is OWASP Dependency Check . There is already a Github Action available for this tool here . In this exercise, integrate this program into your Github workflow and do the validation before you actually deploy resources in AWS. You need to save your report with the following instruction: - name: Archive dependency check reports uses: actions/upload-artifact@v1 with: name: reports path: reports Attention: You will have to install the Node.JS dependencies before running the actual dependency check. You can do this by adding the following lines to your workflow after the checkout action: - uses: actions/checkout@v2 - name: Install NPM dependencies run: | npm install --production --unsafe-perm","title":"3rd Party Dependency Check"},{"location":"dependency-check/#static-code-analysis-with-owasp-dependency-check-1-hour","text":"After scanning your source code with Sonar, we now need to analyze the dependencies of your application, as they can also introduce vulnerabilities to your application. One very famous tool to do so is OWASP Dependency Check . There is already a Github Action available for this tool here . In this exercise, integrate this program into your Github workflow and do the validation before you actually deploy resources in AWS. You need to save your report with the following instruction: - name: Archive dependency check reports uses: actions/upload-artifact@v1 with: name: reports path: reports Attention: You will have to install the Node.JS dependencies before running the actual dependency check. You can do this by adding the following lines to your workflow after the checkout action: - uses: actions/checkout@v2 - name: Install NPM dependencies run: | npm install --production --unsafe-perm","title":"Static Code Analysis with OWASP Dependency Check (1 hour)"},{"location":"docker/","text":"Docker Lab (1 hour) The goal of this exercise is to build your first Docker container. At the end of the lab, you should have a functioning web server based on Node.JS packaged this web server in a Docker image a running a Docker container that you can access from your workstation To perform this lab: Verify that you can log in to the global Docker Registry: docker login Create a directory for this training on your Desktop (e.g. \"CloudAwarenessLab\"). Download the following files in this directory: Dockerfile (the file to build the Docker image) app.js (the application source code) In your terminal, position yourself in the directory: cd c:\\Users\\<loginldap>\\Desktop\\CloudAwarenessLab Open the previously downloaded file \"Dockerfile\" in an editor: the first line states FROM node:alpine In case you wouldn't specify a tag (:alpine), Docker will default to \"latest\". It is a common best-practice to always specify a tag when referencing to an image. you'll also see one line stating ADD app.js . In this step the source code of your Node.JS server is added into . directory, so in the current working directory. you'll also a line with the statement ENTRYPOINT . The entrypoint is the command that is run on your Docker container with the it is launched with the docker run command. Launch the image build process: docker build -t mywebserver:1.0 . The Docker Engine has now built a new Docker image and you can find it in your local registry. To do so, type the following in your terminal: docker images Run the previously built image: docker run -d --rm -p 3000:3000 mywebserver:1.0 The id of the container is returned. The container is started in the background. Notes on the parameters: \" -d \" instructs Docker to run the container as a daemon, so in the background \" --rm \" instructs Docker to delete the container ones it is stopped. Like that, the local registry will not be poluted with \"intermediate\" containers \" -p 3000:3000 \" instructs Docker to expose the containers port 3000 on port 3000 on the host ( Attention : in our case, the host is the Minikube VM) You can check the logs of your running container with: docker logs <id of the container> Your container is running in the VM created by Minikube. As you exposed the port 3000 in the previous step, we now need to find the IP address if your Minikube VM: minikube ip In your browser, open http://minikube-ip:3000 . You should see \"Hello World\" now. Once you are satisfied with the result, you can transfer your image from local Docker registry to the global Docker registry. Do do so, tag your image and push it to docker.io: docker tag mywebserver:1.0 <username>/mywebserver:1.0 docker push <username>/mywebserver:1.0 Attention: For this to work, you will need an account on hub.docker.com You can now stop your container (with the id of the container that was returned to you when you ran it) docker stop <id of the container> Follow up exercise (30 Minutes) After you learned how to build, run and push a Docker image, try to build the same application you saw here in another programming language (preferrably Java).","title":"Docker Lab"},{"location":"docker/#docker-lab-1-hour","text":"The goal of this exercise is to build your first Docker container. At the end of the lab, you should have a functioning web server based on Node.JS packaged this web server in a Docker image a running a Docker container that you can access from your workstation To perform this lab: Verify that you can log in to the global Docker Registry: docker login Create a directory for this training on your Desktop (e.g. \"CloudAwarenessLab\"). Download the following files in this directory: Dockerfile (the file to build the Docker image) app.js (the application source code) In your terminal, position yourself in the directory: cd c:\\Users\\<loginldap>\\Desktop\\CloudAwarenessLab Open the previously downloaded file \"Dockerfile\" in an editor: the first line states FROM node:alpine In case you wouldn't specify a tag (:alpine), Docker will default to \"latest\". It is a common best-practice to always specify a tag when referencing to an image. you'll also see one line stating ADD app.js . In this step the source code of your Node.JS server is added into . directory, so in the current working directory. you'll also a line with the statement ENTRYPOINT . The entrypoint is the command that is run on your Docker container with the it is launched with the docker run command. Launch the image build process: docker build -t mywebserver:1.0 . The Docker Engine has now built a new Docker image and you can find it in your local registry. To do so, type the following in your terminal: docker images Run the previously built image: docker run -d --rm -p 3000:3000 mywebserver:1.0 The id of the container is returned. The container is started in the background. Notes on the parameters: \" -d \" instructs Docker to run the container as a daemon, so in the background \" --rm \" instructs Docker to delete the container ones it is stopped. Like that, the local registry will not be poluted with \"intermediate\" containers \" -p 3000:3000 \" instructs Docker to expose the containers port 3000 on port 3000 on the host ( Attention : in our case, the host is the Minikube VM) You can check the logs of your running container with: docker logs <id of the container> Your container is running in the VM created by Minikube. As you exposed the port 3000 in the previous step, we now need to find the IP address if your Minikube VM: minikube ip In your browser, open http://minikube-ip:3000 . You should see \"Hello World\" now. Once you are satisfied with the result, you can transfer your image from local Docker registry to the global Docker registry. Do do so, tag your image and push it to docker.io: docker tag mywebserver:1.0 <username>/mywebserver:1.0 docker push <username>/mywebserver:1.0 Attention: For this to work, you will need an account on hub.docker.com You can now stop your container (with the id of the container that was returned to you when you ran it) docker stop <id of the container>","title":"Docker Lab (1 hour)"},{"location":"docker/#follow-up-exercise-30-minutes","text":"After you learned how to build, run and push a Docker image, try to build the same application you saw here in another programming language (preferrably Java).","title":"Follow up exercise (30 Minutes)"},{"location":"ecr/","text":"CI with Github Actions and Docker (1 hour) This exercise is building up on exercise 1.4 (Github Actions). The goal of this exercise is to push your previously built Docker image to the public Docker hub: hub.docker.com Performing this step is absolutely necessary for most of the following exercises. The goal of this exercise is to extend your your Github Actions to: Use the Github Action provided by Docker (see documentation here ) Push your image with a unique tag to hub.docker.com (use the GITHUB_SHA environment variable)","title":"CI with Github Actions and Docker"},{"location":"ecr/#ci-with-github-actions-and-docker-1-hour","text":"This exercise is building up on exercise 1.4 (Github Actions). The goal of this exercise is to push your previously built Docker image to the public Docker hub: hub.docker.com Performing this step is absolutely necessary for most of the following exercises. The goal of this exercise is to extend your your Github Actions to: Use the Github Action provided by Docker (see documentation here ) Push your image with a unique tag to hub.docker.com (use the GITHUB_SHA environment variable)","title":"CI with Github Actions and Docker (1 hour)"},{"location":"ecs/","text":"Deploy Containers with ECS (1 hour) This exercise is building up on exercise 1.4 (Github Actions). The goal of this exercise is to deploy your previously built Docker image to the public Docker hub: hub.docker.com First, deploy an ECS cluster with Cloudformation from the following file: ecs-cluster.yaml Choose the default security group, VPC and all subnets The goal of this exercise is to extend your your Github Actions to: Add the following file to your repository ecs-task.yaml Extend your Github flow with the following lines: aws cloudformation deploy --template-file ecs-task.yaml --stack-name ecs-task --parameter-overrides ImageName=docker.io/<your-docker-username>/ssc:sha-$(git rev-parse --short HEAD) --no-fail-on-empty-changeset","title":"Deploy Containers with ECS"},{"location":"ecs/#deploy-containers-with-ecs-1-hour","text":"This exercise is building up on exercise 1.4 (Github Actions). The goal of this exercise is to deploy your previously built Docker image to the public Docker hub: hub.docker.com First, deploy an ECS cluster with Cloudformation from the following file: ecs-cluster.yaml Choose the default security group, VPC and all subnets The goal of this exercise is to extend your your Github Actions to: Add the following file to your repository ecs-task.yaml Extend your Github flow with the following lines: aws cloudformation deploy --template-file ecs-task.yaml --stack-name ecs-task --parameter-overrides ImageName=docker.io/<your-docker-username>/ssc:sha-$(git rev-parse --short HEAD) --no-fail-on-empty-changeset","title":"Deploy Containers with ECS (1 hour)"},{"location":"eks/","text":"EKS Setup (1 hour) You have already experimented with a local Kubernetes installation in the form of Minikube. In the next step, we will set up a managed Kubernetes on AWS. For this, we will use EKS, the Elastic Kubernetes Service. To facilitate the instantiation of Kubernetes, we will use eksctl, a command line tool interact with Kubernetes. To install it, please follow the guidelines here . After the installation, please download the following file: cluster.yaml Attention: It is absolutely necessary that you use the file above for cluster definition. The AWS Educate has certain limitations that makes the \"standard\" installation fail. You can then instantiate an EKS cluster by simply executing the following command: eksctl create cluster -f cluster.yaml After the cluster installation, it's time to extend your Github Actions workflow to launch a deployment in Kubernetes. For this, please download the following files and place them in your repository: kustomization.yaml deployment.yaml You'll need to extend your workflow with the following lines: sed -i \"s#IMAGE_NAME#<add-your-image-name-here>#g\" kustomization.yaml sed -i \"s/IMAGE_TAG/sha-$(git rev-parse --short HEAD)/g\" kustomization.yaml aws eks update-kubeconfig --name isen kubectl kustomize . | kubectl apply -f -","title":"EKS Setup"},{"location":"eks/#eks-setup-1-hour","text":"You have already experimented with a local Kubernetes installation in the form of Minikube. In the next step, we will set up a managed Kubernetes on AWS. For this, we will use EKS, the Elastic Kubernetes Service. To facilitate the instantiation of Kubernetes, we will use eksctl, a command line tool interact with Kubernetes. To install it, please follow the guidelines here . After the installation, please download the following file: cluster.yaml Attention: It is absolutely necessary that you use the file above for cluster definition. The AWS Educate has certain limitations that makes the \"standard\" installation fail. You can then instantiate an EKS cluster by simply executing the following command: eksctl create cluster -f cluster.yaml After the cluster installation, it's time to extend your Github Actions workflow to launch a deployment in Kubernetes. For this, please download the following files and place them in your repository: kustomization.yaml deployment.yaml You'll need to extend your workflow with the following lines: sed -i \"s#IMAGE_NAME#<add-your-image-name-here>#g\" kustomization.yaml sed -i \"s/IMAGE_TAG/sha-$(git rev-parse --short HEAD)/g\" kustomization.yaml aws eks update-kubeconfig --name isen kubectl kustomize . | kubectl apply -f -","title":"EKS Setup (1 hour)"},{"location":"github/","text":"Getting started with Github (1 hour) The goal of this exercise is to upload your current progress into a version control system. For this course, we are using Github.com as a our platform. Within the next one hour, please perform the following steps: Sign Up to Github.com Install git on your workstation Create a new repository with the name \"ssc\". It will serve as the base for the following days and all changes will be stored here Follow the instructions on how to add existing source code into your newly created repository. Perform the indicated steps in the previously created \"CloudAwarenessLab\" folder on your workstation Push your source code into your repository Once this is done, you can take the remaining time and get familiar with the Gitflow best practice here . Ideally, for future labs you will create a new branch for exery exercise and merge it to the Git master through a \"Pull Request\".","title":"Getting Started on Github"},{"location":"github/#getting-started-with-github-1-hour","text":"The goal of this exercise is to upload your current progress into a version control system. For this course, we are using Github.com as a our platform. Within the next one hour, please perform the following steps: Sign Up to Github.com Install git on your workstation Create a new repository with the name \"ssc\". It will serve as the base for the following days and all changes will be stored here Follow the instructions on how to add existing source code into your newly created repository. Perform the indicated steps in the previously created \"CloudAwarenessLab\" folder on your workstation Push your source code into your repository Once this is done, you can take the remaining time and get familiar with the Gitflow best practice here . Ideally, for future labs you will create a new branch for exery exercise and merge it to the Git master through a \"Pull Request\".","title":"Getting started with Github (1 hour)"},{"location":"jenkins/","text":"Jenkins CI Server (1 hour) Throughout the course, you used Github Actions as your CI/CD Platform. In order to give you an overview about the most popular Open Source solution, we will deploy the Jenkins Build server in this Lab. We will use the guideline provided by AWS here . After Jenkins is installed, create your first pipeline as described here .","title":"Jenkins CI Server"},{"location":"jenkins/#jenkins-ci-server-1-hour","text":"Throughout the course, you used Github Actions as your CI/CD Platform. In order to give you an overview about the most popular Open Source solution, we will deploy the Jenkins Build server in this Lab. We will use the guideline provided by AWS here . After Jenkins is installed, create your first pipeline as described here .","title":"Jenkins CI Server (1 hour)"},{"location":"juice-shop/","text":"Juice Shop (1 hour) OWASP Juice Shop is probably the most modern and sophisticated insecure web application! It can be used in security trainings, awareness demos, CTFs and as a guinea pig for security tools! Juice Shop encompasses vulnerabilities from the entire OWASP Top Ten along with many other security flaws found in real-world applications! In this lab, you will deploy the Juice Shop, which we will use in later tutorial to analyze weaknesses. To do so: Fork this repository. Create a Github Workflow that builds the Juice Shop image and pushes it to docker.io Deploy the previously built Juice Shop in your EKS cluster Use the files customization.yaml and deployment.yaml from your previous exercise and adapt the image name","title":"Juice Shop"},{"location":"juice-shop/#juice-shop-1-hour","text":"OWASP Juice Shop is probably the most modern and sophisticated insecure web application! It can be used in security trainings, awareness demos, CTFs and as a guinea pig for security tools! Juice Shop encompasses vulnerabilities from the entire OWASP Top Ten along with many other security flaws found in real-world applications! In this lab, you will deploy the Juice Shop, which we will use in later tutorial to analyze weaknesses. To do so: Fork this repository. Create a Github Workflow that builds the Juice Shop image and pushes it to docker.io Deploy the previously built Juice Shop in your EKS cluster Use the files customization.yaml and deployment.yaml from your previous exercise and adapt the image name","title":"Juice Shop (1 hour)"},{"location":"kaniko/","text":"Docker Security with Kaniko (1 hour) Interacting with the Docker engine directly through the docker command line tool can impose a significant security thread. In order to improve this risk and limit access to the Docker engine, there are several projects that allow building Docker images without a Docker engine. One of them is kaniko , which you will use to build and push a Docker image to ECR. We will use Jenkins and our previously created EKS cluster in order to build highly secure and scalable build system. As the setup will be rather complex, before we begin, please have a look at the following graphic that will visualize our final setup: To do so, please follow these steps: Create an Elastic Container Repository Repository Go to the AWS Console and open the ECR menu (by searching for Elastic Container Registry) Click on \"Create repository\" Enter \"juice-shop\" and click on \"Create Repository\" Add new permissions to your EKS Node Group Go to the AWS Console and open the IAM menu Go to Roles Search for \"NodeInstanceRole\" Select the NodeInstanceRole and click the button \"Attach policies\" Search for \"Container\" Check \"AmazonEC2ContainerRegistryPowerUser\" Click on \"Attach Policy\" Create an IAM Role for your Jenkins EC2 Instance Go to your AWS Console and open the IAM menu Go to Roles Click on \"Create role\" Click on \"EC2\" and confirm with \"Next: Permissions\" Click on \"Next: Tags\" Click on \"Next: Review\" Give it the name \"role-jenkins-master\" Go to the EC2 menu Select your Jenkins EC2 instance and click on \"Actions\" -> \"Instance Settings\" -> \"Attach/Replace IAM Role\" and select the previously created role from the drop-down menu. Update the aws-auth ConfigMap in your EKS cluster From your workstation, enter the following command: kubectl edit cm aws-auth -n kube-system and add the following entry to the mapRoles section: - groups: - system:masters rolearn: arn:aws:iam::XXXXXXXXXXXX:role/role-jenkins-master username: system:node: {{ EC2PrivateDNSName }} where XX... is your AWS Account ID For your information, the AWS Account ID can be found in the IAM Menu on the bottom left corner, where it's written \"AWS account ID\" (a 12 digit number). Update your Jenkins Security Group In the EC2 Console, open the security group that you assigned to your Jenkins EC2 Instance Allow requests on port 8080 and 50000 from anywhere (Attention, this is not best practice and we only do this for the purpose of the course) Create a new kubeconfig and upload it to the Jenkins Kubernetes Plugin In your workstation, enter the following command: aws eks update-kubeconfig --kubeconfig config-for-jenkins --name isen A new file with the name \"config-for-jenkins\" will be created in your current directory. You'll need it in the next step. Install the Jenkins Kubernetes Plugin In your Jenkins, go to \"Settings\" and select \"Manage plugins\". Click on the tab \"Available\" and search for \"Kubernetes plugin\" Check it and click \"Install\". In the next screen, select to restart Jenkins after installation. Configure the Kubernetes Plugin In Jenkins, go \"Settings\" and select \"Manage nodes\" Click on \"Configure Clouds\" Click on \"Add cloud\" and select \"Kubernetes\". Click on \"Kubernetes Cloud details...\" In Kubernetes namespace, enter \"default\" Next to Credentials, click on \"Add\" and select \"Jenkins\". As Kind, choose \"Secret file\" and in the file row, upload the file config-for-jenkins file that you created in step 5 Confirm with \"Add\" and choose the uploaded file as credential. Check the field \"Direct connection\". Click on \"Save\". Configure the Jenkins Agent Port In Jenkins, go \"Settings\" and select \"Global Security Settings\". In the section \"Agents\", select the \"Fixed\" option and enter 50000 as value. Create a docker-config ConfigMap in Kubernetes Save the following file as docker-config.yaml on your PC: apiVersion : v1 kind : ConfigMap metadata : name : docker - config data : config . json : |- { \"credHelpers\" : { \"XXXXXXXXXXXX.dkr.ecr.us-east-1.amazonaws.com\" : \"ecr-login\" } } Replace XX... with your AWS Account ID Create this file in your Kubernetes cluster by entering: kubectl create -f docker-config.yaml After all these steps are done, you can create a pipeline with the example below: pipeline { agent { kubernetes { // cloud 'kubernetes' yaml \"\"\" kind: Pod metadata: name: kaniko spec: containers: - name: kaniko image: gcr.io/kaniko-project/executor:debug-539ddefcae3fd6b411a95982a830d987f4214251 imagePullPolicy: Always command: - cat tty: true volumeMounts: - name: docker-config mountPath: /kaniko/.docker volumes: - name: docker-config configMap: name: docker-config \"\"\" } } stages { stage ( 'Build with Kaniko' ) { steps { git 'https://github.com/<your-github-username>/juice-shop' container ( name : 'kaniko' ) { sh ''' /kaniko/executor --dockerfile `pwd`/Dockerfile --context `pwd` --destination=XXXXXXXXXXXX.dkr.ecr.us-east-1.amazonaws.com/juice-shop:latest --destination=XXXXXXXXXXXX.dkr.ecr.us-east-1.amazonaws.com/juice-shop:v$BUILD_NUMBER ''' } } } } } Please replace XX... with your AWS Account ID. Bonus task: Deploy this new container image in your EKS cluster. Files that you need to deploy (with kubectl apply -f <file.yaml> ): role.yaml role-binding.yaml You need to replace your pipeline to take the deployment into account. An example pipeline can be found here: pipeline.groovy","title":"Build Docker with Jenkins and Kaniko"},{"location":"kaniko/#docker-security-with-kaniko-1-hour","text":"Interacting with the Docker engine directly through the docker command line tool can impose a significant security thread. In order to improve this risk and limit access to the Docker engine, there are several projects that allow building Docker images without a Docker engine. One of them is kaniko , which you will use to build and push a Docker image to ECR. We will use Jenkins and our previously created EKS cluster in order to build highly secure and scalable build system. As the setup will be rather complex, before we begin, please have a look at the following graphic that will visualize our final setup: To do so, please follow these steps: Create an Elastic Container Repository Repository Go to the AWS Console and open the ECR menu (by searching for Elastic Container Registry) Click on \"Create repository\" Enter \"juice-shop\" and click on \"Create Repository\" Add new permissions to your EKS Node Group Go to the AWS Console and open the IAM menu Go to Roles Search for \"NodeInstanceRole\" Select the NodeInstanceRole and click the button \"Attach policies\" Search for \"Container\" Check \"AmazonEC2ContainerRegistryPowerUser\" Click on \"Attach Policy\" Create an IAM Role for your Jenkins EC2 Instance Go to your AWS Console and open the IAM menu Go to Roles Click on \"Create role\" Click on \"EC2\" and confirm with \"Next: Permissions\" Click on \"Next: Tags\" Click on \"Next: Review\" Give it the name \"role-jenkins-master\" Go to the EC2 menu Select your Jenkins EC2 instance and click on \"Actions\" -> \"Instance Settings\" -> \"Attach/Replace IAM Role\" and select the previously created role from the drop-down menu. Update the aws-auth ConfigMap in your EKS cluster From your workstation, enter the following command: kubectl edit cm aws-auth -n kube-system and add the following entry to the mapRoles section: - groups: - system:masters rolearn: arn:aws:iam::XXXXXXXXXXXX:role/role-jenkins-master username: system:node: {{ EC2PrivateDNSName }} where XX... is your AWS Account ID For your information, the AWS Account ID can be found in the IAM Menu on the bottom left corner, where it's written \"AWS account ID\" (a 12 digit number). Update your Jenkins Security Group In the EC2 Console, open the security group that you assigned to your Jenkins EC2 Instance Allow requests on port 8080 and 50000 from anywhere (Attention, this is not best practice and we only do this for the purpose of the course) Create a new kubeconfig and upload it to the Jenkins Kubernetes Plugin In your workstation, enter the following command: aws eks update-kubeconfig --kubeconfig config-for-jenkins --name isen A new file with the name \"config-for-jenkins\" will be created in your current directory. You'll need it in the next step. Install the Jenkins Kubernetes Plugin In your Jenkins, go to \"Settings\" and select \"Manage plugins\". Click on the tab \"Available\" and search for \"Kubernetes plugin\" Check it and click \"Install\". In the next screen, select to restart Jenkins after installation. Configure the Kubernetes Plugin In Jenkins, go \"Settings\" and select \"Manage nodes\" Click on \"Configure Clouds\" Click on \"Add cloud\" and select \"Kubernetes\". Click on \"Kubernetes Cloud details...\" In Kubernetes namespace, enter \"default\" Next to Credentials, click on \"Add\" and select \"Jenkins\". As Kind, choose \"Secret file\" and in the file row, upload the file config-for-jenkins file that you created in step 5 Confirm with \"Add\" and choose the uploaded file as credential. Check the field \"Direct connection\". Click on \"Save\". Configure the Jenkins Agent Port In Jenkins, go \"Settings\" and select \"Global Security Settings\". In the section \"Agents\", select the \"Fixed\" option and enter 50000 as value. Create a docker-config ConfigMap in Kubernetes Save the following file as docker-config.yaml on your PC: apiVersion : v1 kind : ConfigMap metadata : name : docker - config data : config . json : |- { \"credHelpers\" : { \"XXXXXXXXXXXX.dkr.ecr.us-east-1.amazonaws.com\" : \"ecr-login\" } } Replace XX... with your AWS Account ID Create this file in your Kubernetes cluster by entering: kubectl create -f docker-config.yaml After all these steps are done, you can create a pipeline with the example below: pipeline { agent { kubernetes { // cloud 'kubernetes' yaml \"\"\" kind: Pod metadata: name: kaniko spec: containers: - name: kaniko image: gcr.io/kaniko-project/executor:debug-539ddefcae3fd6b411a95982a830d987f4214251 imagePullPolicy: Always command: - cat tty: true volumeMounts: - name: docker-config mountPath: /kaniko/.docker volumes: - name: docker-config configMap: name: docker-config \"\"\" } } stages { stage ( 'Build with Kaniko' ) { steps { git 'https://github.com/<your-github-username>/juice-shop' container ( name : 'kaniko' ) { sh ''' /kaniko/executor --dockerfile `pwd`/Dockerfile --context `pwd` --destination=XXXXXXXXXXXX.dkr.ecr.us-east-1.amazonaws.com/juice-shop:latest --destination=XXXXXXXXXXXX.dkr.ecr.us-east-1.amazonaws.com/juice-shop:v$BUILD_NUMBER ''' } } } } } Please replace XX... with your AWS Account ID. Bonus task: Deploy this new container image in your EKS cluster. Files that you need to deploy (with kubectl apply -f <file.yaml> ): role.yaml role-binding.yaml You need to replace your pipeline to take the deployment into account. An example pipeline can be found here: pipeline.groovy","title":"Docker Security with Kaniko (1 hour)"},{"location":"kubernetes/","text":"Kubernetes Lab (1 hour) In this lab, you will deploy your previously created Docker image in Kubernetes. The goal of this lab is to show you the usage of Kubernetes deployments and services how to use Kubernetes scaling capabilites how to access a service deployed in Kubernetes Application Deployment Verify that you can access Kubernetes: kubectl version If you see a Server Version like below, it means your Kubernetes CLI can connect to your Kubernetes VM: $ kubectl version Client Version: version.Info { Major: \"1\" , Minor: \"13\" , GitVersion: \"v1.13.10\" , GitCommit: \"37d169313237cb4ceb2cc4bef300f2ae3053c1a2\" , GitTreeState: \"clean\" , BuildDate: \"2019-08-19T10:52:43Z\" , GoVersion: \"go1.11.13\" , Compiler: \"gc\" , Platform: \"linux/amd64\" } Server Version: version.Info { Major: \"1\" , Minor: \"13\" , GitVersion: \"v1.13.10\" , GitCommit: \"37d169313237cb4ceb2cc4bef300f2ae3053c1a2\" , GitTreeState: \"clean\" , BuildDate: \"2019-08-19T10:44:49Z\" , GoVersion: \"go1.11.13\" , Compiler: \"gc\" , Platform: \"linux/amd64\" } Download the following file to your \"CloudAwarenessLab\" folder: deployment.yaml Open the file in an editor and verify that the image: key is referencing your previously built image Deploy your application with the following command: kubectl apply -f deployment.yaml Verify that your application is running properly: kubectl get deployment You shoud now see one running Pod , which is scheduled by the Deployment that you just created. You can also check the running Pods in your Kubernetes cluster by typing: kubectl get pods This will give a list of running instances (a.k.a. Pods) of your application. Write down the name of the Pod, you'll need it later for reference. In order to access your application, you have to deploy a Kubernetes service. Download the following file your \"CloudAwarenessLab\" folder: service.yaml and apply the following command: kubectl apply -f service.yaml You have now deployed a so called NodePort Kubernetes Service . It opens a dedicated port on your Minikube VM, through which you can access the according service. You can find the associated port number by typing: kubectl get svc In the example below, the port number would be 31478 : $ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE kubernetes ClusterIP 10 .96.0.1 <none> 443 /TCP 126d webserver-service NodePort 10 .98.147.142 <none> 80 :31478/TCP 4s In your browser, open the IP of your Minikube VM (which you retrieved in the previous lab) and add the port that you retrieved from the last command, e.g.: http://minikube-ip:31478 . You should see \"Hello World\" example from before, but it's hosted in Kubernetes. You should also see that the hostname is equal to the Pod name that you wrote down earlier. Application Scaling Now you'll see the scaling capabilities of Kubernetes. Enter the following command: kubectl scale deployment/webserver-deployment --replicas=3 With this command, you update the Kubernetes Deployment and instruct it to have a total of three replicas. Kubernetes will handle that by instantiating two additional Pods . Refresh your browser serveral times and monitor how the hostname of your microservice changes. Congratulations, you just learned how to scale a service in Kubernetes. Application Configuration For the next step, we we'll see how to configure an application in Kubernetes. You might have noticed that in the app.js file, we are defining an environment variable GREETING with the default value Hello World . In a first step, we will change the Kubernetes the Kubernetes deployment and add environment variable section the Pod template: kubectl edit deployment webserver-deployment and add the env section like described below: spec : containers : - image : mywebserver : 1.0 imagePullPolicy : IfNotPresent name : webserver env : - name : GREETING value : \"I'm configured now\" Refresh your browser, and see how to greeting changed. Now let's use another mean to configure our application: the Kubernetes ConfigMap . Download the sample ConfigMap to your \"CloudAwarenessLab\" folder: configmap.yaml This way, you can decouple the application from the deployment configuration and therefore ease the reusability of your application. You can deploy the ConfigMap with the following command: kubectl apply -f configmap.yaml Now, you'll have to modify your deployment in order to consume the ConfigMap: kubectl edit deployment webserver-deployment And edit the file in the following way: spec : containers : - image : mywebserver : 1.0 imagePullPolicy : IfNotPresent name : webserver env : - name : GREETING valueFrom : configMapKeyRef : name : webserver - configmap key : greeting Application Secrets Kubernetes also supports objects of the type Secret , that are meant to store sensitive data. Secrets can either be injected as environment variables or mounted in the Pods filesystem. As you already learned how to inject environment variables, let's now inject the Kubernetes secret as a file into our pod. Deploy a secret in our Kubernetes cluster: kubectl create secret generic webserver-secret --from-literal=secret.txt=\"Well done!\" Update your Pod definiton to mount the webserver-secret secret in /var/secret/ : kubectl edit deployment webserver-deployment And edit the file in the following way: spec : containers : - image : mywebserver : 1.0 imagePullPolicy : IfNotPresent name : webserver volumeMounts : - name : webserver - secret mountPath : \"/var/secret\" readOnly : true volumes : - name : webserver - secret secret : secretName : webserver - secret Refresh your browser, and see how the greeting changed. Follow up exercise (30 Minutes) Try to launch a database in Kubernetes and connect an application with this database. A simple example can be found here . It's written in Node.JS and uses MongoDB.","title":"Kubernetes Lab"},{"location":"kubernetes/#kubernetes-lab-1-hour","text":"In this lab, you will deploy your previously created Docker image in Kubernetes. The goal of this lab is to show you the usage of Kubernetes deployments and services how to use Kubernetes scaling capabilites how to access a service deployed in Kubernetes","title":"Kubernetes Lab (1 hour)"},{"location":"kubernetes/#application-deployment","text":"Verify that you can access Kubernetes: kubectl version If you see a Server Version like below, it means your Kubernetes CLI can connect to your Kubernetes VM: $ kubectl version Client Version: version.Info { Major: \"1\" , Minor: \"13\" , GitVersion: \"v1.13.10\" , GitCommit: \"37d169313237cb4ceb2cc4bef300f2ae3053c1a2\" , GitTreeState: \"clean\" , BuildDate: \"2019-08-19T10:52:43Z\" , GoVersion: \"go1.11.13\" , Compiler: \"gc\" , Platform: \"linux/amd64\" } Server Version: version.Info { Major: \"1\" , Minor: \"13\" , GitVersion: \"v1.13.10\" , GitCommit: \"37d169313237cb4ceb2cc4bef300f2ae3053c1a2\" , GitTreeState: \"clean\" , BuildDate: \"2019-08-19T10:44:49Z\" , GoVersion: \"go1.11.13\" , Compiler: \"gc\" , Platform: \"linux/amd64\" } Download the following file to your \"CloudAwarenessLab\" folder: deployment.yaml Open the file in an editor and verify that the image: key is referencing your previously built image Deploy your application with the following command: kubectl apply -f deployment.yaml Verify that your application is running properly: kubectl get deployment You shoud now see one running Pod , which is scheduled by the Deployment that you just created. You can also check the running Pods in your Kubernetes cluster by typing: kubectl get pods This will give a list of running instances (a.k.a. Pods) of your application. Write down the name of the Pod, you'll need it later for reference. In order to access your application, you have to deploy a Kubernetes service. Download the following file your \"CloudAwarenessLab\" folder: service.yaml and apply the following command: kubectl apply -f service.yaml You have now deployed a so called NodePort Kubernetes Service . It opens a dedicated port on your Minikube VM, through which you can access the according service. You can find the associated port number by typing: kubectl get svc In the example below, the port number would be 31478 : $ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE kubernetes ClusterIP 10 .96.0.1 <none> 443 /TCP 126d webserver-service NodePort 10 .98.147.142 <none> 80 :31478/TCP 4s In your browser, open the IP of your Minikube VM (which you retrieved in the previous lab) and add the port that you retrieved from the last command, e.g.: http://minikube-ip:31478 . You should see \"Hello World\" example from before, but it's hosted in Kubernetes. You should also see that the hostname is equal to the Pod name that you wrote down earlier.","title":"Application Deployment"},{"location":"kubernetes/#application-scaling","text":"Now you'll see the scaling capabilities of Kubernetes. Enter the following command: kubectl scale deployment/webserver-deployment --replicas=3 With this command, you update the Kubernetes Deployment and instruct it to have a total of three replicas. Kubernetes will handle that by instantiating two additional Pods . Refresh your browser serveral times and monitor how the hostname of your microservice changes. Congratulations, you just learned how to scale a service in Kubernetes.","title":"Application Scaling"},{"location":"kubernetes/#application-configuration","text":"For the next step, we we'll see how to configure an application in Kubernetes. You might have noticed that in the app.js file, we are defining an environment variable GREETING with the default value Hello World . In a first step, we will change the Kubernetes the Kubernetes deployment and add environment variable section the Pod template: kubectl edit deployment webserver-deployment and add the env section like described below: spec : containers : - image : mywebserver : 1.0 imagePullPolicy : IfNotPresent name : webserver env : - name : GREETING value : \"I'm configured now\" Refresh your browser, and see how to greeting changed. Now let's use another mean to configure our application: the Kubernetes ConfigMap . Download the sample ConfigMap to your \"CloudAwarenessLab\" folder: configmap.yaml This way, you can decouple the application from the deployment configuration and therefore ease the reusability of your application. You can deploy the ConfigMap with the following command: kubectl apply -f configmap.yaml Now, you'll have to modify your deployment in order to consume the ConfigMap: kubectl edit deployment webserver-deployment And edit the file in the following way: spec : containers : - image : mywebserver : 1.0 imagePullPolicy : IfNotPresent name : webserver env : - name : GREETING valueFrom : configMapKeyRef : name : webserver - configmap key : greeting","title":"Application Configuration"},{"location":"kubernetes/#application-secrets","text":"Kubernetes also supports objects of the type Secret , that are meant to store sensitive data. Secrets can either be injected as environment variables or mounted in the Pods filesystem. As you already learned how to inject environment variables, let's now inject the Kubernetes secret as a file into our pod. Deploy a secret in our Kubernetes cluster: kubectl create secret generic webserver-secret --from-literal=secret.txt=\"Well done!\" Update your Pod definiton to mount the webserver-secret secret in /var/secret/ : kubectl edit deployment webserver-deployment And edit the file in the following way: spec : containers : - image : mywebserver : 1.0 imagePullPolicy : IfNotPresent name : webserver volumeMounts : - name : webserver - secret mountPath : \"/var/secret\" readOnly : true volumes : - name : webserver - secret secret : secretName : webserver - secret Refresh your browser, and see how the greeting changed.","title":"Application Secrets"},{"location":"kubernetes/#follow-up-exercise-30-minutes","text":"Try to launch a database in Kubernetes and connect an application with this database. A simple example can be found here . It's written in Node.JS and uses MongoDB.","title":"Follow up exercise (30 Minutes)"},{"location":"network-policies/","text":"Kubernetes Network Policies (30 minutes) As you saw throughout the course, Kubernetes separates projects through the notion of namespaces . By default, Kubernetes enables Pods to communicate between namespaces, which goes against of the security principles that you learned about earlier: Least privilege. As a reminder, it is a security best practice to only allow the absolute necessary. There is a very good Github project visualizing the different network policy configurations here . Your exercise is the apply the different configurations and test them accordingly. It should give you a good overview on how to apply Kubernetes network policies in real life.","title":"Kubernetes Network Policies"},{"location":"network-policies/#kubernetes-network-policies-30-minutes","text":"As you saw throughout the course, Kubernetes separates projects through the notion of namespaces . By default, Kubernetes enables Pods to communicate between namespaces, which goes against of the security principles that you learned about earlier: Least privilege. As a reminder, it is a security best practice to only allow the absolute necessary. There is a very good Github project visualizing the different network policy configurations here . Your exercise is the apply the different configurations and test them accordingly. It should give you a good overview on how to apply Kubernetes network policies in real life.","title":"Kubernetes Network Policies (30 minutes)"},{"location":"prerequisites/","text":"Prerequisites (1 hour) Please follow the instructions on this page carefully, as they will help you avoiding obstacles in the next exercices. The goal of the prerequisite step is to provide you a fully working development environment, containing Docker and Kubernetes. Attention: If you are using Windows 10 or Mac, you can also use Docker Desktop in place of minikube. In order to achieve that, you'll be guided through the following steps: Install Chocolatey, a Package Manager for Windows With Chocolatey, you will install the following packages on your workstation: VirtualBox, a VM Manager Docker CLI and Kubernetes CLI Minikube, a tool that helps you installing a Docker and Kubernetes Development environment Python, a programming language that you'll need later in the course AWS CLI, you'll need it later in the course With Minikube, you will install a Virtual Machine in VirtualBox, containing Docker and Kubernetes The diagram on the bottom of this page is designed to help you to understand how Windows, your VM, Docker and Kubernetes are interacting. To perform this lab: Install Chocolatey according to the instructions here . You do not have to enter your email address in the first step. Launch a terminal with Windows Administrator rights and install Minikube, Kubectl (the Kubernetes CLI) and the Docker CLI with the help of Chocolatey: choco install -y python virtualbox minikube kubernetes-cli docker awscli Launch Minikube: minikube --docker-env HTTP_PROXY=\"http://<isen-proxy-host>:<isen-proxy-port>\" --docker-env HTTPS_PROXY=\"http://<isen-proxy-host>:<isen-proxy-port>\" --docker-env NO_PROXY=\"127.0.0.1,192.168.99.0/24,10.0.0.0/8\" start Notes on the parameters: As we are in a universtiy network, we need to configure docker engine in the virtual machine to perform outgoing internet connection through this proxy. Certain hosts do not need to be accessed through the proxy, which is configured through the \"NO_PROXY\" parameter. In our case, this is: localhost (127.0.0.1) the network between your local VMs (192.168.99.0/24), the network range normally used for intranet (10.0.0.0/8) In order for Minikube to download the according VM image, you may have to configure the proxy on your workstation as well: For Windows Terminal: set HTTP_PROXY=http://<isen-proxy-host>:<isen-proxy-port> set HTTPS_PROXY=http://<isen-proxy-host>:<isen-proxy-port> set NO_PROXY=127.0.0.1,192.168.99.0/24,10.0.0.0/8 For Shell (Cygwin, Git Bash): export HTTP_PROXY=http://<isen-proxy-host>:<isen-proxy-port> export HTTPS_PROXY=http://<isen-proxy-host>:<isen-proxy-port> export NO_PROXY=127.0.0.1,192.168.99.0/24,10.0.0.0/8 After Minikube is launched, it can be necessary to configure your Docker CLI and Kubernetes CLI on your workstation. This configuration is done through environment variables, which can be set with the following commands: This has to be done every time you open a new terminal. For Windows Terminal: @FOR /f \"tokens=*\" %i IN ('minikube docker-env') DO @%i For Shell (Cygwin, Git Bash): eval(minikube docker-env) or eval $(minikube docker-env) Verify that you can access the Docker CLI: docker info Verify that you can access the Kubernetes CLI: kubectl version Below you can see an diagram of your workstation setup, which should help you understanding how the different components are interacting:","title":"Prerequisites"},{"location":"prerequisites/#prerequisites-1-hour","text":"Please follow the instructions on this page carefully, as they will help you avoiding obstacles in the next exercices. The goal of the prerequisite step is to provide you a fully working development environment, containing Docker and Kubernetes. Attention: If you are using Windows 10 or Mac, you can also use Docker Desktop in place of minikube. In order to achieve that, you'll be guided through the following steps: Install Chocolatey, a Package Manager for Windows With Chocolatey, you will install the following packages on your workstation: VirtualBox, a VM Manager Docker CLI and Kubernetes CLI Minikube, a tool that helps you installing a Docker and Kubernetes Development environment Python, a programming language that you'll need later in the course AWS CLI, you'll need it later in the course With Minikube, you will install a Virtual Machine in VirtualBox, containing Docker and Kubernetes The diagram on the bottom of this page is designed to help you to understand how Windows, your VM, Docker and Kubernetes are interacting. To perform this lab: Install Chocolatey according to the instructions here . You do not have to enter your email address in the first step. Launch a terminal with Windows Administrator rights and install Minikube, Kubectl (the Kubernetes CLI) and the Docker CLI with the help of Chocolatey: choco install -y python virtualbox minikube kubernetes-cli docker awscli Launch Minikube: minikube --docker-env HTTP_PROXY=\"http://<isen-proxy-host>:<isen-proxy-port>\" --docker-env HTTPS_PROXY=\"http://<isen-proxy-host>:<isen-proxy-port>\" --docker-env NO_PROXY=\"127.0.0.1,192.168.99.0/24,10.0.0.0/8\" start Notes on the parameters: As we are in a universtiy network, we need to configure docker engine in the virtual machine to perform outgoing internet connection through this proxy. Certain hosts do not need to be accessed through the proxy, which is configured through the \"NO_PROXY\" parameter. In our case, this is: localhost (127.0.0.1) the network between your local VMs (192.168.99.0/24), the network range normally used for intranet (10.0.0.0/8) In order for Minikube to download the according VM image, you may have to configure the proxy on your workstation as well: For Windows Terminal: set HTTP_PROXY=http://<isen-proxy-host>:<isen-proxy-port> set HTTPS_PROXY=http://<isen-proxy-host>:<isen-proxy-port> set NO_PROXY=127.0.0.1,192.168.99.0/24,10.0.0.0/8 For Shell (Cygwin, Git Bash): export HTTP_PROXY=http://<isen-proxy-host>:<isen-proxy-port> export HTTPS_PROXY=http://<isen-proxy-host>:<isen-proxy-port> export NO_PROXY=127.0.0.1,192.168.99.0/24,10.0.0.0/8 After Minikube is launched, it can be necessary to configure your Docker CLI and Kubernetes CLI on your workstation. This configuration is done through environment variables, which can be set with the following commands: This has to be done every time you open a new terminal. For Windows Terminal: @FOR /f \"tokens=*\" %i IN ('minikube docker-env') DO @%i For Shell (Cygwin, Git Bash): eval(minikube docker-env) or eval $(minikube docker-env) Verify that you can access the Docker CLI: docker info Verify that you can access the Kubernetes CLI: kubectl version Below you can see an diagram of your workstation setup, which should help you understanding how the different components are interacting:","title":"Prerequisites (1 hour)"},{"location":"psp/","text":"Kubernetes Pod Security Policies (30 minutes) In order to start, please read carefully the instructions on Pod Security Policies in EKS provided here You will have to delete the default eks.privileged Pod Security Policy before you can apply the example provided below. Please follow the example provided by Kubernetes here Please revert your Pod Security Policy to the standard eks.privileged after you performed the exercise. The description how to do so is mentioned on the bottom of the first page.","title":"Kubernetes Pod Security Policies"},{"location":"psp/#kubernetes-pod-security-policies-30-minutes","text":"In order to start, please read carefully the instructions on Pod Security Policies in EKS provided here You will have to delete the default eks.privileged Pod Security Policy before you can apply the example provided below. Please follow the example provided by Kubernetes here Please revert your Pod Security Policy to the standard eks.privileged after you performed the exercise. The description how to do so is mentioned on the bottom of the first page.","title":"Kubernetes Pod Security Policies (30 minutes)"},{"location":"sonar/","text":"Static Code Analysis with Sonar and PMD (1 hour) The first thing you need to scan in your application is your actual source code. One very famous tool to do so is Sonarqube . There is already a Github Action available for this tool here . For this tutorial, you need to create an account on sonarcloud.io . In this exercise, integrate this action into your Github workflow and do the validation before you actually deploy resources in AWS. Also, fix all issues that are reported through the scanner. Another tool to scan your source for vulnerabilities is PMD . It can be good to use several different source code scanners in order to find the maximum number of vulnerabilities and improve the quality of your code. There is already a Github Action available for PMD here . Your exercise is to integrate this tool into your Github workflow.","title":"Static Code Analysis"},{"location":"sonar/#static-code-analysis-with-sonar-and-pmd-1-hour","text":"The first thing you need to scan in your application is your actual source code. One very famous tool to do so is Sonarqube . There is already a Github Action available for this tool here . For this tutorial, you need to create an account on sonarcloud.io . In this exercise, integrate this action into your Github workflow and do the validation before you actually deploy resources in AWS. Also, fix all issues that are reported through the scanner. Another tool to scan your source for vulnerabilities is PMD . It can be good to use several different source code scanners in order to find the maximum number of vulnerabilities and improve the quality of your code. There is already a Github Action available for PMD here . Your exercise is to integrate this tool into your Github workflow.","title":"Static Code Analysis with Sonar and PMD (1 hour)"},{"location":"zapproxy/","text":"Dynamic Application Security Scanning (1 hour) Until now you scanned your application in a static way, meaning you found vulnerabilties before an artifact was actually built. A complementary way to uncover weaknesses is the Dynamic Application Security Scanning , also known as DAST. One famous scanner is the OWASP ZAP Proxy. Your task is now to integrate the ZAP Proxy Github Action here in your Github workflow.","title":"Dynamic Application Security Scanning"},{"location":"zapproxy/#dynamic-application-security-scanning-1-hour","text":"Until now you scanned your application in a static way, meaning you found vulnerabilties before an artifact was actually built. A complementary way to uncover weaknesses is the Dynamic Application Security Scanning , also known as DAST. One famous scanner is the OWASP ZAP Proxy. Your task is now to integrate the ZAP Proxy Github Action here in your Github workflow.","title":"Dynamic Application Security Scanning (1 hour)"}]}